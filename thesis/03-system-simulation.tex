\chapter{System Performance Analysis and Simulation}
\label{chapter:system-performance-analysis-and-simulation}
In this thesis, we study and evaluate the performance analysis methods of a modern packet processing system. This chapter introduces the modeling, measurement, and simulation methods used in our work.

We will start by introducing the common performance analysis methods and metrics, and then further examine the modeling and simulation techniques. Further, we present the queueing and resource networks, which are fundamental concepts for modeling packet processing systems. We will describe the basic concepts of simulation, the primary method for solving more complex networks needed to model modern packet processing systems. We end the chapter with a short survey of the existing simulation software.

% Our evaluations are based on the modeling and simulation techniques, while measurements are needed to build the model. Similarly to many other packet processing system studies~\cite{cavium:2010:fundamentals}, we are mostly interested in the communication delays, namely throughput and latency, of the system.

\section{Performance Analysis}
For almost every computer system -- whether it be a high performance application on the cloud~\cite{jackson:2010:HPCOC} or an army fuel-supply system~\cite{sabuncuoglu:2005:TAS} -- the performance is one of the most sought-after criterion. To achieve the highest performance for the lowest cost, different performance evaluation techniques are required at different system life cycle stages. The choice of evaluation criteria and techniques used to evaluate the system performance vary between systems. These two choices are discussed in the following subsections.~\cite{jain:1991:AOCSPA}

\subsection{Evaluation Techniques}
Performance evaluation can be done using various techniques. These techniques are generally divided into three categories: analytical modeling, simulation, and measurement. The former two techniques are based on symbolic models of the real-life system, whereas the measurements are done on the system itself. Analytical approaches use mathematical methods to solve the model, and simulation imitates the operation of the system by executing the model on a simulator~\cite{Banks:2010:DES}. Measurements are done by instrumenting the real system with various hardware and software tools.~\cite{jain:1991:AOCSPA}

No strict programmatic rules can be given to select the right technique. However, there are some considerations that can be used to guide the decisions: system life-cycle stage; available resources, such as time, money and tools; required level of accuracy; trade-off evaluation; and saleability.~\cite{jain:1991:AOCSPA}

The life-cycle stage of the system is usually the first to consider. In early design stage, the evaluation is often done by using analytical methods or simulation, as it is impossible to measure a yet non-existing system. Measurements are, thus, often used for improving existing systems.~\cite{jain:1991:AOCSPA}

Available resources also dictate the technique selection. Running the measurements and simulations are often more time consuming~\cite{Fujimoto:1990:PDE} than the analytic approach, and the required time can be difficult to predict. They both also require special equipment and tools, which are expensive and need special skills to operate. The analytical methods are generally considered less time consuming and less expensive than measurement and simulation.~\cite{jain:1991:AOCSPA}

An important thing to note about the simulation software is their parallelization. Managing the events of, and monitoring during, the simulation, in addition to the challenging in parallel computing itself, make the scaling of simulation software extremely complex.~\cite{Fujimoto:1990:PDE}

The required level of accuracy should also be considered. For analytical models to be solvable, they often have to be very simple abstractions of the original system. Thus, the results of the analytical methods are often approximate and less accurate than simulation or measurement. Simulations, like analytical methods, are abstract, but often much closer to the real system. Even measurements, depsite being most accurate of these methods, can produce results that do not agree with the actual system behavior. The accuracy of simulations and measurements can often be enhanced by spending more time and money on them.~\cite{jain:1991:AOCSPA}

Different evaluation techniques are often used together. Taking advantage of two or more methods simultaneously can be used to validate and verify the analysis results. On the other hand, different methods can be used to complement each other to enhance the analysis process.~\cite{jain:1991:AOCSPA}

\subsection{Performance Metrics}
Every performance study needs a set of performance criteria or metrics, which vary with the service provided by the system. Service requests made to the system produce different outcomes: the system either performs the service -- correctly or incorrectly -- or refuses to perform it. The metrics associated with these outcomes are called speed, reliability, and availability, respectively.~\cite{jain:1991:AOCSPA}

When the service result is correct, the performance metrics are used to measure the responsiveness, productivity and utilization of the system. For example, in a network packet processing system, responsiveness could be measured as the packet response time, productivity as the throughput, and utilization as the percentage of time the cores are busy~\cite{cavium:2010:fundamentals}.~\cite{jain:1991:AOCSPA}

If the service result is incorrect, the metrics describe the probabilities of the error, for example, how probably an unintentional packet drops or out-of-orderings occur. When the system fails to perform requested service, it is helpful the classify the different causes of failure, and determine the probability and the duration for each.~\cite{jain:1991:AOCSPA}

It should be noted that many systems provide multiple services, and the number of metrics can be large. Also, different evaluation techniques provide different metrics at different times of the service. For example, some simulators allow white-box-like view of the system states during the simulation, whereas, with analytical methods, the details of the system are often unavailable.~\cite{jain:1991:AOCSPA}

\section{Resource Networks}
Network structures are often used for describing the models. For example petri nets~\cite{Peterson:1981:Petri}, markov chains~\cite{Bolch:2006:Queueing}, queuing networks~\cite{Bolch:2006:Queueing}, and resource networks~\cite{Menasce:1994:CPP} are widely researched model definitions with a well-developed theory for analyzing the system behavior.

Queue based modeling schemes are inherent in packet processing systems performance analysis. Queueing networks is a specific modeling concept, in which the system under study is represented with a restricted set of building blocks: tasks, queues, resources, and routes. The tasks traverse through the system, possibly queueing for, and consuming the resources along their way, based on the routing definitions. Each resource has a queue associated to it, where the tasks wait for the required resource to be available.~\cite{Bolch:2006:Queueing}

The resource queues can have various scheduling disciplines, such as first in first out (FIFO), last in first out (LIFO), priority, or shortest task first.\todo{add more stuff about queue disciplines} The queueing network models are often solved analytically or simulated, to find the equilibrium or transient state of the system.\todo{explain the pros and cons of different solutions, emphasize the strict queue disciplines for analytical solutions}~\cite{Bolch:2006:Queueing}

Queueing networks can be used to describe various systems, and many different problems have well studied, efficient queueing networks solutions for them. However, the lack of simulation time task routing and detailed monitoring, and confined resource descriptions, make queueing networks unsuitable for more complex computing system studies.~\cite{Bolch:2006:Queueing}

Resource networks extend the queueing networks concept by decoupling the network into resource usage network and resource provision network, and introducing a passive resource type. The resource usage network is a directed graph, describing the possible paths and resource usage requests for the tasks. Resource provision networks are similar to the traditional queueing networks, describing the available resources and their interconnections in the system. Resource networks also enable new task control mechanisms such as fork-join and branching. ~\cite{Menasce:1994:CPP}

Resource networks are suitable for modeling resource requests, dynamic scheduling and different load balancing schemes. These techniques enable modeling of more complex interactions of parallel systems with dynamic workload and resource usage. Due to the dynamicity introduced by the flexibility, resource networks often have to be solved by simulation.~\cite{Menasce:1994:CPP}

\section{Simulation}
This sections describes the basic principles related to simulation. Note that, despite the most of the examples in this chapter being about computing, simulation is widely used also in several other contexts, even beyond science. The concepts described below, e.g. entities, attributes, or activities, have different realizations from system to system.

Simulation is an artificial imitation of the operation of a real-life system over time. The system behavior is studied by developing a simulation model, based on a set assumptions concerning the characteristics and functions of the system. The assumptions are presented in mathematical, logical, and symbolic relationships between the objects of interest of the system. An artificial operation history is generated by executing the simulation model, generally on a simulator program, with respect to system input and time. Data are collected from the simulation similarly as if the real system was being measured.

\subsection{System components and environment}
\label{sec:syst-comp-envir}

In simulation, a \emph{system} is defined to be a set of objects that work together, in regular interaction or interdependence, to accomplish some goal or purpose. Every system is a subsystem of broader \emph{system environment}, whose changes can affect the system. For every simulation study, a \emph{boundary} between the system and its environment must be set.~\cite{Banks:2010:DES}

For example, computer systems are often enormously complex. The complexity is managed by designing them as a hierarchy of smaller subsystems, and combining them with compatible interfaces. In a study of a network processing system, such Cavium OCTEON's~\cite{cavium:2010:fundamentals}, the higher level system can be viewed to consist of several processors, auxiliary memory, memory controllers, and other smaller subsystems. These subsystems can further be viewed as a set of smaller subsystems of subsystems: the processor has several processing cores, each core consists of different functional units, and each functional unit consists of logical circuitry.~\cite{Banks:2010:DES}

The objects of interest in a system are called \emph{entities}, which are associated with a set \emph{attributes}. An \emph{activity} is a specified length time period. A system \emph{state} completely describes the system at any given time of a specific study. The state might be changed by an immediate occurrences called \emph{events}. The events affecting the system are divided into two groups by their source: \emph{endogenous} events occur within the system under study, and \emph{exogenous} events occur in the system environment.~\cite{Banks:2010:DES}

Continuing with the above example, each of the mentioned components can be seen as the entities of the system. There are several activities and events at different levels of the system. At the higher level, these can be seen as the packets flowing through the system: writes and reads to the memory, execution on different processors, and queueing for the processor time. At a lower level, these could be the computation done by the logical units or the flipping of the transistors' state.

Systems can be categorized into discrete and continuous systems, as per the type of their state change. In a \emph{discrete system}, the state changes only at a discrete time points, and in a \emph{continuous system}, the state change is continuous over time. In practice, almost every system is a combination of both continuous and discrete changes. These systems are often classified by their dominant type.~\cite{Banks:2010:DES}

\subsection{Simulation Model}
\label{sec:simulation-model}

Simulation \emph{model} is a representation of either hypothetical or real-life system under study. By its definition~\cite{Encyclopedia of computer science}, the model should be a simplified representation of the original system. In simulation, it should represent the studied system with enough detail to provide relevant conclusions and, at the same time, only consider those details that affect the investigated problem. The decision between the level of accuracy and abstraction usually requires knowledge of the system under modeling.~\cite{Banks:2010:DES}

Like with the system representation, the basic building blocks of the simulation model are entities, attributes, activities and events. The model does not necessarily contain the exact replica of the components of the system, but rather simplified components that represent the system with enough detail.~\cite{Banks:2010:DES}

In the example study of network processing unit, the likely goals would be to determine the packet throughput and latency of the system. In that case, the system could be modeled with sufficient accuracy by omitting all the lower level details of the CPU. On the other hand, a detailed performance study of a specific CPU might require even the minute details of the functional units or logical circuitry.~\cite{Magnusson:2002:Simics, Hughes:2002:Rsim}

The models may be categorized as being static or dynamic, and deterministic or stochastic. Static simulation models represent a steady-state time-invariant systems, whereas the dynamic simulation models represent systems as time-variant. Deterministic models contain no random variables, meaning that for the known set of inputs the simulation result will be a unique set of outputs. Stochastic models on the other hand include random variables, thus leading to a random set of outputs.~\cite{Banks:2010:DES}

Simulation models are further divided into discrete and continuous, analogously with the discrete and continuous systems described in Section~\ref{sec:syst-comp-envir}. However, it is possible to model continuous systems with discrete models, and vice versa. Just as the real-life systems, the simulation models can be a mix of both continuous and discrete models.~\cite{Banks:2010:DES}

Three different simulation advancement designs are presented in~\cite{peros:2009:simulation}: event-advance, unit-time advance and activity based. In event-advance design the system state changes only when the event occurs. Thus the system state advances from snapshot to snapshot, meaning that the state is unchanged between two successive events. In unit-time advance design, the master clock is advanced in fixed time increments. Activity based design is a continuous design method, which models the system as a set of conditions that determine when the activities start or stop.~\cite{peros:2009:simulation}

\subsection{Monitoring}
To make conclusions about simulation, the information about the simulation system needs to be gathered. Similarily to the measurement based techniques, the system is instrumented and the data are saved during the execution. The constructed simulation model is simulated, and the execution is monitored to gather metrics of interest.~\cite{jain:1991:AOCSPA, peros:2009:simulation}

There are two generally used approaches for gathering simulation metrics: trace-based and on-the-fly. The tracing approaches produce raw data from the execution, which are then often post-processed in suitable way. In on-the-fly approaches, the simulator program aggregates the data during the simulation, thus reducing the amount of output.~\cite{jain:1991:AOCSPA, peros:2009:simulation}

\section{Modeling and Simulation Software}

% Java Modelling Tools,[java modeling tools http://jmt.sourceforge.net/] a GPL suite of queueing theory tools written in Java
% Queueing Package for GNU Octave~\cite{Marzolla:2010:QPGNU}

% TODO:
% - tÃ¤ssÃ¤ voisi miettiÃ¤ jotain korkeamman tason jaottelua erityyppisten simulaationsoftien vÃ¤lille
% - sitten voisi antaa konkreettisia esimerkkejÃ¤ kustakin
% - voisi pohtia erilaisten mallinnusmekanismien ilmaisuvoimaa (primÃ¤Ã¤riÃ¤ kÃ¤yttÃ¶kohdetta, simulaationopeutta, mallinnustehokkuutta, jne.)

In~\cite{Austin:2002:SimpleScalar}, Austin et al. present three drivers for measuring simulator software model: performance, flexibility, and detail. Performance refers to the amount of simulation the model per resources. Flexibility describes how customizable the simulator software is, in terms of modeling. Lastly, detail refers to the level of abstraction used in the simulator. In theory, a simulator software could exist, that fulfills all these characteristics at the same time. However, in practice, at least one of them is missing.~\cite{Austin:2002:SimpleScalar}

Partly because of this, no single general purpose simulator exists. On the contrary, there are a multitude of different simulators design with different goals in mind. On a high level, the simulator software can be categorized as cycle accurate, functional, and high level simulators.

The lowest level cycle accurate simulators are mainly used in low level hardware designs, and microarchitectural optimizations. At this level, the hardware execution can be modeled precisely, at the cost of simulation speed. As the simulation is carried out on a software, it is typically orders of magnitudes slower than the execution on real hardware. They are also difficult to maintain, and thus, in many applications this level simulators are too fine detailed. The hardware models at this levels are typically described with special purpose hardware design languages such as VHDL or Verilog.~\cite{Patterson:2007:Computer, Weaver:2008:Cycle}

One abstraction level higher, functional simulators are used to simulate the system architecture together with execution of program binaries. They are typically used to measure how applications behave on certain hardware. For example, GPGPU-Sim and Barra, used to simulate NVIDIA graphics processing units, are functional simulations. They both can execute CUDA code, and thus can be used to evaluate the performance of different GPU software implementations. Most of the simulation related to existing MPSoC devices are done on the functional level.~\cite{Lopez:2015:GPGPUSIM}

While cycle accurate and functional simulators are important part of design and optimization of hardware and software, in many situations, higher level simulation is needed. On higher level, the applications and hardware are of presented with coarse abstractions of the underlying system details, to enable early design space exploration of non-existing systems.

This thesis provides an example of a discrete event simulator, PSE, used for modeling packet processing applications in fog computing context. However, the breadth of different systems in fog and cloud computing field is enormous, and PSE is only one example amongst many others. Again, these simulators are build on different abstraction levels, ranging from more detailed (functional) simulators for specific computing units in datacenters, to higher level simulators capable of simulating interrelations of multple full scale datacenters.

There are several simulators targeted for simulation of cloud computing datacenters on different level. CloudSim~\cite{Calheiros:2011:Cloudsim} is an extensible toolset for modeling and simulation of cloud computing infrastructure and application services, originally released and developed by the University of Melbourne. CloudSim can be used for simulating large scale datacenters, virtualized server hosts with customizable provisioning policies, energy-aware computational resources, data center network topologies and message-passing applications. Companies such as Hewlett Packard use CloudSim for simulating resource provisioning, energy efficiency, optimization, and further research.

Various different projects extend the CloudSim API for advanced cloud computing simulations. For example, CloudSimEx~\cite{CloudSimEx} enables MapReduce simulation capabilities and parallel simulations, Cloud2Sim~\cite{Kathiravelu:2014:Concurrent} enables simulation execution on multiple distributed servers, and CloudAnalyst~\cite{Wickremasinghe:2010:CloudAnalyst} enables simulation of large-scale cloud applications in terms of geographic distribution of both servers and workloads.

Some simulator software, such as Greencloud~\cite{Kliazovich:2010:GreenCloud}, are designed for the measuring the energy and power consumption of different datacenter setups. GreenCloud provides tools for simulating CPI, memory, storage, and networking resources, with Independent energy models for each resource. It also supports virtualization and virtual machine migration, and full TCP/IP implementation.

\todo[inline]{should this be extended/fixed?}


% Different cloud simulation tools:
% CloudSim
% CloudAnalyst
% GreenCloud
% iCanCloud
% MDCSim
% NetworkCloudSim
% VirtualCloud

% Simulation provides cost savings and speeds the development in high level system such as cloud datacenters, and low level systems like network processors.

% cloudsim================================
% CloudSim is an extensible toolset for modeling and simulation of cloud computing infrastructure and application services, developed originally released and developed by the University of Melbourne. CloudSim can be used for simulating large scale cloud datacenters.~\cite{Calheiros:2011:Cloudsim}

% Java based, no GUI. Latest release 3.0.3 (May 2013)
% HP and other organizations using cloudsim for for example resource provisioning, energy efficiency, optmization, and further research.

% It allows simulation of ``of different kinds of resource leasing scenarios under varying load and pricing distributions''

% ``
% support for modeling and simulation of large scale Cloud computing data centers
% support for modeling and simulation of virtualized server hosts, with customizable policies for provisioning host resources to virtual machines
% support for modeling and simulation of energy-aware computational resources
% support for modeling and simulation of data center network topologies and message-passing applications
% support for modeling and simulation of federated clouds
% support for dynamic insertion of simulation elements, stop and resume of simulation
% support for user-defined policies for allocation of hosts to virtual machines and policies for allocation of host resources to virtual machines''

% CloudSim 3.0 released at Jan 13. 2012.

% \todo[inline]{CloudSim: Provides tools for simulation IaaS.
%   Provides configuration for data centers, hosts and virtual machines.
% Different policies for creating host VM's, assigning VM's to hosts, VM resource allocation etc
% }
% ================
% cloudanalyst===========================
% easy to use GUI
% Flebility through High degree of configurability
% simulation of large-scale cloud applications, including geographic location of both datacenter and workloads.
% Built on top of cloudsim
% =============================
% greencloud=======================
% detailed cloud simulator, enables observing, interacting and measuring cloud performance.
% ``sophisticated opensource simulator''
% born in the GreenIT project
% Enables measuring the cloudservers' energy efficiency (precise energy models, and power saving modes for DNS and DVFS)
% Writte in C++/OTcl
% Open source
% Extension to a well-known NS2 network simulator
% All the communication is simulated on the packet level, enabling detailed network simulation -> supports for example TCP/IP protocol simulation
% ================================
% icancloud ================================
% Developed at the University of Madrid
% Enables prediction of the trade-offs between cost and performance of applications and hardware used in the datacenter
% Provides built-in models of the Amazon's instance types.
% Flexible hypervisor module -> enables fast modeling of uni-core/manycore systems
% GUI
% ===================================


% \todo[inline]{Rsim: More detailed hardware simulation, with focus on ILP effects of processors
%       Detailed shared-memory multiprocessor models
%       They show that the previous simple-processor-models cannot demonstrate the complicated dynamically scheduled processors with sufficient detail.}

% \todo[inline]{Simics: ``Reliable performance estimates require simulation of the full system''
%         Their simulator includes device models accurate enough to run unmodified operating system kernels, firmware and device driver.
%         They simulate a network of heterogeneous computers.
%         Commercial product
%         Two dimensional classification:
%           scope (what is modeled),
%           abstraction level (level at which the system is modeled)
%             two perspectives: functional, timing (performance)}

% \todo[inline]{SimpleScalar:
%   Hardware development is often accelerated by software simulations of the hardware under development.
%   Basic idea: Implement a software model of the hardware, stress then with appropriate workload
%   Gains: The availability of the simulation model is much faster than building the hardware. Thus the hardware can be tested faster. Shorter time to market, cut down development costs.
%   Simulation modeling is driven by three factors: performance, flexibility, detail
%     Performance measures the system's ability to process workload
%     Flexibility reflects the ability to modify the models, enabling measurements of different designs
%     Detail means the level of abstraction the model captures from the actual system
%     -> Getting all three is hard, practically impossible.
%     -> trade offs}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis-hartikainen"
%%% End:
