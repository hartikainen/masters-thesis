\subsection{Stream Computing}
In traditional computing architectures, such as Von Neumann architecture, the computation is based on reading, processing and writing the data located in system's memory. These architectures have their limitations and thus both the academia and the industry are researching alternative ways of computing. One of the alternatives is stream computing, which is present especially in Internet of Things (IoT) applications. In stream computing, the computation is done for data streams flowing through the system, instead of being altered in the memory.

\subsection{Programming methods}
The performance gains in today's computing rely heavily on parallelism and concurrency of programs. The parallel computation itself, especially on heterogeneous hardware, is a hard problem due to the non-determinism, communication (memory) delays and complicated memory management. Most widely adopted  parallel programming approach, threads, are becoming inefficient and thus new approaches, such as task parallelism, have been developed. This raises the question of how to balance the computation between the computing resources to maximize the utilization.
%[Lee et al. Problem with Threads]

Parallel computation and heterogeneous MPSoC devices are important parts of today's efficient computing systems. However, they also bring out new challenges in the software development and requirements for the programming models. The scalability of the

Distributing the stream computation is non-trivial, due to its real time nature. Traditional computing clusters can be virtualized, alleviating the distribution of the computation, by using message passing abstractions such as Message Passing Interface (MPI). However, the real time nature of stream computation makes its distribution difficult. Data processed in stream computation is often dynamic: the stream characteristics are not known in advance, and the data volume and the computation requirements can change at any point of the computation. Load-balancing of the computation has to be done on the fly, and thus the communication delays and latencies between the nodes are important.

%%TODO: ``from threads to tasks'' ja ``context-swithing overhead''
% Hardware threads are static, meaning that they cannot adapt to the dynamic changes of the workload. Also, the hardware threads cannot be migrated between the computing nodes, and thus binding the computation to hardware threads forces the computation to be done on the specific computing node. This is why



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis-plan-hartikainen"
%%% End:
