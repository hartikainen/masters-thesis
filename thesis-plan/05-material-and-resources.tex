Vesa Hirvisalo will work as an advisor for this thesis. Jussi Hanhirova is working on his doctoral thesis on the same area of research. Risto Vuorio is working on his Master's thesis on the similar subject. The supervisor is still yet to be decided. Hardware and frameworks to be used in the thesis is listed below.

\begin{itemize}
\item Cavium OCTEON II: MPSoC blade with aspecial purpose hardware accelerators and 32 MIPS cores.

\item Intel DPDK: a set of packet prosessing libraries and drivers.

\item MPI (Message Passing Interface): De-facto standard for message-passing system to write portable message-passing programs.

\item OpenEM (Open Event-Machine): Architectural abstraction and framework of event-driven multicore computation.

\item OpenMP (Open Multi-Processing): Multi-platform, Shared memory multiprocessing API, a thread-parallelism implementation.

\item PSE (Performance Simulation Environment): A toolset for analyzing hardware and software co-scheduled manycore systems.
\end{itemize}

\subsection{Open Event Machine}
Open Event Machine (OpenEM), originally developed by Nokia Solutions and Networks (NSN) is a framework and programming model for a task (event) based processing on a multicore platforms. It enables efficient writing of dynamically load-balanced multicore applications with a very low overhead run-to-completion principle. OpenEM can be implemented both, on bare hardware as well as on top of an operating system.

OpenEM applications are constructed from three main parts, namely execution objects (EO), events, and event queues. Events are the main communication blocks, the data, of OpenEM. Execution object is a run-to-completion object, or a function [TODO: mention context], that is run using the event as the argument. Event queues are used to store the events between execution objects. The scheduling order of the events, from the queues to the EO's, are handled by the OpenEM scheduler. Neither the application nor the EO's are tied to a specific core. The dynamic load-balancing is achieved by processing EO's with the events on any available core at the time.

The user is able to guide the scheduling of the events through the EO's coremask parameters, and queue's priority and type parameters. The coremask parameter for the EO's specifies which cores each the EO is allowed to be run on (no restrictions by default). The queue type can be atomic, parallel, or parallel ordered, and the priority order of the queues can be specified by the priority parameter. In addition to the user specified parameters, the scheduling is guided by the locality of the EO, meaning that tasks to be processed on the same EO are more likely to be scheduled consecutively in cases where the other priorities are equal. Also, the task order is maintained through the queue in a FIFO principle.

\subsection{Message Passing Interface}
Message Passing Interface (MPI) is a specification and de facto standard for a set of message passing libraries. MPI standard defines the syntax and semantics for functions that are useful in a portable message-passing and distributed memory programs.

\subsection{Performation Simulation Environment}
Performation Simulation Environment (PSE) is a heterogeneous modeling and simulation environment, based on a Queuing Network Simulation (QSE) tool built at Aalto (TKK).

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis-plan-hartikainen"
%%% End:
